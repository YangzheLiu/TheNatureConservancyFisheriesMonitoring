{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import h5py\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Reshape, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.optimizers import Adadelta, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, History\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import pandas as pd\n",
    "from __future__ import division, print_function\n",
    "from collections import Counter\n",
    "import ujson as json\n",
    "import PIL\n",
    "import random\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "DATA_HOME_DIR = ROOT_DIR + '/data'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "data_path = DATA_HOME_DIR + '/' \n",
    "full_train_path = data_path + 'train_org/'\n",
    "crop_path = data_path + 'cropped/'\n",
    "split_train_path = data_path + 'train/'\n",
    "valid_path = ROOT_DIR + '/valid/data/train/'\n",
    "test_path = DATA_HOME_DIR + '/test2/'\n",
    "\n",
    "# data\n",
    "classes = [\"ALB\", \"BET\", \"DOL\", \"LAG\", \"OTHER\", \"SHARK\", \"YFT\"]\n",
    "nb_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_dict = defaultdict(str)\n",
    "\n",
    "for fp in glob.glob(full_train_path + '*/*g'):\n",
    "    cls = fp.split('/')[-2]\n",
    "    im = fp.split('/')[-1]\n",
    "    class_dict[im] = cls\n",
    "    \n",
    "print(\"Image Records:\", len(class_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, batch_size=4, class_mode='categorical',\n",
    "                target_size=(224,224),classes=None):\n",
    "    return gen.flow_from_directory(dirname, target_size=target_size, class_mode=class_mode, shuffle=shuffle, batch_size=batch_size,classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classes(trn_path, val_path, test_path):\n",
    "    batches = get_batches(trn_path, shuffle=False, batch_size=1, target_size=(224,224))\n",
    "    val_batches = get_batches(val_path, shuffle=False, batch_size=1, target_size=(224,224))\n",
    "    test_batches = get_batches(test_path, shuffle=False, batch_size=1, target_size=(224,224))\n",
    "    return val_batches.filenames, batches.filenames, test_batches.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_filenames, filenames, test_filenames = get_classes(split_train_path, valid_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_filenames = [f.split('/')[-1] for f in filenames]\n",
    "raw_test_filenames = [f.split('/')[-1] for f in test_filenames]\n",
    "raw_val_filenames = [f.split('/')[-1] for f in val_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anno_classes = ['alb', 'bet', 'dol', 'lag', 'other', 'shark', 'yft']\n",
    "bb_json = {}\n",
    "\n",
    "for c in anno_classes:\n",
    "    j = json.load(open('bb_annotations/{}.json'.format(c), 'r'))\n",
    "    for l in j:\n",
    "        if 'annotations' in l.keys() and len(l['annotations'])>0:\n",
    "            bb_json[l['filename'].split('/')[-1]] = sorted(\n",
    "                l['annotations'], key=lambda x: x['height']*x['width'])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fns = glob.glob(full_train_path + '*/*.jpg')\n",
    "    \n",
    "for fn in fns:\n",
    "    f_id = fn.split(\"/\")[-1]\n",
    "    im = PIL.Image.open(fn)\n",
    "    width, height = im.size\n",
    "    \n",
    "    if not f_id in bb_json.keys():\n",
    "        bb_json[f_id] = {\"height\": 0, \"width\": 0, \"x\": 0, \"y\": 0, \"size\": im.size}\n",
    "    else:\n",
    "        anno = bb_json[f_id]\n",
    "        x, y = anno[\"x\"], anno[\"y\"]\n",
    "        bb_json[f_id] = {\"height\": anno[\"height\"], \"width\": anno[\"width\"], \"x\": x, \"y\": y, \"size\": im.size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "bb_params = ['height', 'width', 'x', 'y']\n",
    "def convert_bb(bb,resized_width=224.,resized_height=224.):\n",
    "    cropsize = 224\n",
    "    size = bb[\"size\"]\n",
    "    bb = [bb[p] for p in bb_params]\n",
    "    \n",
    "    # conversion factors\n",
    "    conv_x = (resized_width / size[1])\n",
    "    conv_y = (resized_height / size[0])\n",
    "    \n",
    "    # make the size conversions\n",
    "    height = bb[0]*conv_x\n",
    "    width = bb[1]*conv_y\n",
    "    x = bb[2]*conv_y\n",
    "    y = bb[3]*conv_x\n",
    "    \n",
    "    # offset/padding adjustments\n",
    "    x = max(x , 0)\n",
    "    y = max(y , 0)\n",
    "    \n",
    "#     if x + cropsize > width:\n",
    "#         x = width - cropsize\n",
    "#     if y + cropsize > height:\n",
    "#         y = height - cropsize\n",
    "    \n",
    "    bb[0] = int(height)\n",
    "    bb[1] = int(width)\n",
    "    bb[2] = int(x)\n",
    "    bb[3] = int(y)\n",
    "    return bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_bbox = np.stack([convert_bb(bb_json[f]) for f in raw_filenames]).astype(np.float32)\n",
    "val_bbox = np.stack([convert_bb(bb_json[f]) for f in raw_val_filenames]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(path, target_size=(360,640)):\n",
    "    batches = get_batches(path, shuffle=False, batch_size=1, class_mode=None, target_size=target_size)\n",
    "    return np.concatenate([batches.next() for i in range(batches.nb_sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_category(path, target_size=(1,1)):\n",
    "    batches = get_batches(path, shuffle=False, batch_size=1,classes=['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT'], target_size=target_size)\n",
    "    return np.concatenate([batches.next()[1] for i in range(batches.nb_sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smp_class = get_category(valid_path)\n",
    "trn_class = get_category(split_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smp = get_data(valid_path,target_size=(1,1))\n",
    "trn = get_data(split_train_path,target_size=(1,1))\n",
    "\n",
    "# smp = get_data(valid_path,target_size=(360,640))\n",
    "# trn = get_data(split_train_path,target_size=(360,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_rect(bb, color='red'):\n",
    "    return plt.Rectangle((bb[2], bb[3]), bb[1], bb[0], color=color, fill=False, lw=3)\n",
    "\n",
    "def show_bb(i):\n",
    "    bb = trn_bbox[i]\n",
    "    plot(trn[i])\n",
    "    plt.gca().add_patch(create_rect(bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_plot(img):\n",
    "    return np.rollaxis(img, 0, 3).astype(np.uint8)\n",
    "\n",
    "def plot(img):\n",
    "    plt.imshow(to_plot(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_coordinates(bbox):\n",
    "    height = bbox[0]\n",
    "    width = bbox[1]\n",
    "    \n",
    "    #bottom left\n",
    "    x0 = bbox[2] \n",
    "    y0 =  bbox[3]\n",
    "\n",
    "    return [[x0,y0],[x0+width,y0],[x0+width,y0+height],[x0,y0+height]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# polygon_test = []\n",
    "\n",
    "# polygon_test.append(np.array(get_coordinates(val_bbox[14]),np.int32))\n",
    "# # polygon_test\n",
    "\n",
    "# mask = np.zeros((360, 640), dtype=\"int32\")\n",
    "# mask = cv2.fillPoly(mask, np.int32(polygon_test),255)\n",
    "# plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_bbox = [convert_bb(bb_json[f],resized_width=22,resized_height=40) for f in raw_filenames]\n",
    "val_bbox = [convert_bb(bb_json[f],resized_width=22,resized_height=40) for f in raw_val_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trn_targets = []\n",
    "val_targets = [] \n",
    "\n",
    "\n",
    "#training bboxes\n",
    "for i,b in enumerate(trn_bbox):\n",
    "    \n",
    "    #get individual fish bboxes\n",
    "    mask_patches = []\n",
    "    mask_patches.append(np.array(get_coordinates(trn_bbox[i]),np.int32))    \n",
    "    \n",
    "    \n",
    "    mask = np.zeros((22, 40), dtype=\"int32\")\n",
    "    \n",
    "    mask = cv2.fillPoly(mask, np.int32(mask_patches),255)\n",
    "    trn_targets.append(mask)\n",
    "    \n",
    "    \n",
    "#validation bboxes\n",
    "for i,b in enumerate(val_bbox):\n",
    "    \n",
    "    mask_patches = []\n",
    "    mask_patches.append(np.array(get_coordinates(val_bbox[i]),np.int32))\n",
    "        \n",
    "        \n",
    "    mask = np.zeros((22, 40), dtype=\"int32\")\n",
    "    mask = cv2.fillPoly(mask, np.int32(mask_patches),255)\n",
    "    val_targets.append(mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1]\n",
    "\n",
    "def VGG_16(size=(224, 224), weights_path='data/vgg16_bn_conv.txt'):\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3,)+size))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask based model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nf=128; p=0.6\n",
    "\n",
    "size = (360, 640)\n",
    "model = VGG_16(size=size)\n",
    "\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.pop()\n",
    "\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Convolution2D(nf,3,3, activation='relu', border_mode='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Dropout(p/3))\n",
    "\n",
    "model.add(Convolution2D(nf,3,3, activation='relu', border_mode='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Dropout(p))\n",
    "\n",
    "model.add(Convolution2D(nf,3,3, activation='relu', border_mode='same'))\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(Dropout(p/2))\n",
    "        \n",
    "model.add(Convolution2D(1,3,3, border_mode='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(Adam(lr=0.00001), loss='mean_squared_error', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_targets = np.array(trn_targets)\n",
    "val_targets = np.array(val_targets)\n",
    "\n",
    "trn_reshaped = trn_targets.reshape(trn_targets.shape[0],1,trn_targets.shape[1],trn_targets.shape[2])\n",
    "val_reshaped = val_targets.reshape(val_targets.shape[0],1,val_targets.shape[1],val_targets.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(trn, trn_reshaped, batch_size=8, nb_epoch=5, \n",
    "             validation_data=(smp, val_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('mask_crop_fish_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_biggest_contour(contours):\n",
    "    \n",
    "    # nofish? \n",
    "    \n",
    "    \n",
    "#     if len(contours) == 1 :\n",
    "#         return 0\n",
    "    \n",
    "    #if more than one contour, find the biggest contour surface\n",
    "    biggest_contour_index = -1 \n",
    "    biggest_contour_surface = 0\n",
    "\n",
    "    i = 0\n",
    "    for c in contours:\n",
    "        # compute the center of the contour\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > biggest_contour_surface:\n",
    "            biggest_contour_surface = area\n",
    "            biggest_contour_index = i\n",
    "        i += 1\n",
    "        \n",
    "    return biggest_contour_index        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path = DATA_HOME_DIR+\"/test2/test_stg2/\"\n",
    "export_path = DATA_HOME_DIR+'/cropped_nof_excl2/'\n",
    "\n",
    "crop_width = 800\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_test_samples = len(glob.glob('data/test2/*/*.jpg'))\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.1,\n",
    "#         rotation_range=10.,\n",
    "#         width_shift_range=0.2,\n",
    "#         height_shift_range=0.2,\n",
    "#         horizontal_flip=True)\n",
    "    \n",
    "    \n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "            'data/test2/',\n",
    "            target_size=size,\n",
    "            batch_size=16,\n",
    "            shuffle = False,\n",
    "            classes = None,\n",
    "            class_mode = None)\n",
    "\n",
    "test_image_list = test_generator.filenames\n",
    "predictions = model.predict_generator(test_generator, nb_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,t in enumerate(raw_test_filenames):\n",
    "    \n",
    "    \n",
    "    if i < 289: #remove this to generate all crops\n",
    "        continue\n",
    "        \n",
    "        \n",
    "        \n",
    "    test_img = cv2.imread(test_path+t)\n",
    "    img_width = test_img.shape[1]\n",
    "    img_height = test_img.shape[0]\n",
    "    \n",
    "#     plt.imshow(test_img)\n",
    "    #predict\n",
    "    inp = np.expand_dims(conv_test_feat[i], 0)\n",
    "    conv = conv_fn([inp,0])[0, 0] #conf_fn shape (1, 1, 22, 40)\n",
    "    cm = scipy.misc.imresize(conv, (img_height,img_width), interp='nearest')\n",
    "    \n",
    "    #find contours\n",
    "    ret, thresh = cv2.threshold(cm, 200, 255, 0)\n",
    "    im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    \n",
    "    #find center of the biggest contour\n",
    "\n",
    "    i = find_biggest_contour(contours)\n",
    "    M = cv2.moments(contours[i])\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    \n",
    "    #calculate boundries of bounding box\n",
    "    x = max(cX - crop_width/2, 0)\n",
    "    y = max(cY - crop_width/2, 0)\n",
    "\n",
    "    if x + crop_width > img_width:\n",
    "        x = img_width - crop_width\n",
    "    if y + crop_width > img_height:\n",
    "        y = img_height - crop_width\n",
    "        \n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "\n",
    "    \n",
    "###### plot bounding box    \n",
    "#     cv2.rectangle(cm,(x,y),(x+crop_width,y+crop_width),color=(255, 255, 255))\n",
    "#     plt.imshow(cv2.drawContours(cm, [contours[i]], -1, (0, 255, 0), 2))\n",
    "\n",
    "##### crop the image and save\n",
    "    crop_img = test_img[y:y+crop_width, x:x+crop_width]\n",
    "#     plt.imshow(crop_img)\n",
    "#     cv2.imwrite(export_path+t,crop_img)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window based model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "size = (360, 640)\n",
    "model = VGG_16(size=size)\n",
    "\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.pop()\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "x_bb=Dense(4)(model.output)\n",
    "x_class=Dense(8,activation='softmax')(model.output)\n",
    "model=Model(model.input,[x_bb,x_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=['mse','categorical_crossentropy'],loss_weights=[.001,1.], optimizer=Adam(lr=0.00001), \\\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist = model.fit(\n",
    "        trn,\n",
    "        [trn_bbox,trn_class],\n",
    "        batch_size=16,\n",
    "        nb_epoch=1,\n",
    "        validation_data=(smp,[val_bbox,smp_class]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist.history['acc']); plt.plot(hist.history['val_acc']);\n",
    "plt.title('model accuracy'); plt.ylabel('accuracy');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist.history['loss']); plt.plot(hist.history['val_loss']);\n",
    "plt.title('model loss'); plt.ylabel('loss');\n",
    "plt.xlabel('epoch'); plt.legend(['train', 'valid'], loc='upper left');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('crop_fish_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(smp[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_bb_pred(i):\n",
    "    bb = val_bbox[i]\n",
    "    bb_pred = pred[0][i]\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plot(smp[i])\n",
    "    ax=plt.gca()\n",
    "    ax.add_patch(create_rect(bb_pred, 'yellow'))\n",
    "    ax.add_patch(create_rect(bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show first 15 results\n",
    "\n",
    "for i in range(0,15):\n",
    "    show_bb_pred(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# crop result\n",
    "\n",
    "crop_width=450\n",
    "for i,t in enumerate(train_name_list):\n",
    "    \n",
    "    test_img = cv2.imread(t)\n",
    "    img_width = test_img.shape[1]\n",
    "    img_height = test_img.shape[0]\n",
    "    \n",
    "#     plt.imshow(test_img)\n",
    "    #predict\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    #find center of the biggest contour\n",
    "\n",
    "\n",
    "    cX = int(bb_json[t.split('/')[-1]]['x']+bb_json[t.split('/')[-1]]['width']/2.)\n",
    "    cY = int(bb_json[t.split('/')[-1]]['y']+bb_json[t.split('/')[-1]]['height']/2.)\n",
    "    \n",
    "    \n",
    "    #calculate boundries of bounding box\n",
    "    x = max(cX - crop_width/2, 0)\n",
    "    y = max(cY - crop_width/2, 0)\n",
    "\n",
    "#     if x + crop_width > img_width:\n",
    "#         x = img_width - crop_width\n",
    "#     if y + crop_width > img_height:\n",
    "#         y = img_height - crop_width\n",
    "        \n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "\n",
    "    \n",
    "###### plot bounding box    \n",
    "#     cv2.rectangle(cm,(x,y),(x+crop_width,y+crop_width),color=(255, 255, 255))\n",
    "#     plt.imshow(cv2.drawContours(cm, [contours[i]], -1, (0, 255, 0), 2))\n",
    "\n",
    "##### crop the image and save\n",
    "    crop_img = test_img[y:y+crop_width, x:x+crop_width]\n",
    "#     plt.imshow(crop_img)\n",
    "    cv2.imwrite(t,crop_img)\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
